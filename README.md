# NLP-Based Resume Screening and Ranking System

## ğŸ“Œ Overview
This project automates resume screening by using **Natural Language Processing (NLP)** and **machine learningâ€“based text similarity** to match candidate resumes with a job description. It objectively scores and ranks resumes, reducing manual effort and improving hiring efficiency.

---

## âš™ï¸ How It Works
- Reads a job description and extracts required skills.
- Converts resume PDFs into text and cleans the data.
- Extracts candidate skills, experience, and contact details.
- Uses **TF-IDF** vectorization and **cosine similarity** to compute match scores.
- Stores results in an **SQLite database**.
- Exports ranked candidates as a **CSV file**.

---

## ğŸ› ï¸ Tech Stack
- **Language:** Python  
- **NLP / ML:** TF-IDF, Cosine Similarity (Scikit-learn)  
- **Text Processing:** Regex, custom cleaning pipeline  
- **Database:** SQLite  
- **Data Handling:** Pandas  
- **PDF Parsing:** PyPDF2  

---

## âœ… Key Features
- Automated resume screening
- Objective, data-driven ranking
- Modular and scalable design
- Recruiter-friendly CSV output

## Architecture Overview

- **OCR / Parsing**: Extract text from resume PDFs.
- **NLP Preprocessing**: Clean text (lowercasing, punctuation & stopword removal).
- **Feature Extraction**: Extract skills, experience, and basic metadata.
- **Vectorization**: TF-IDF vectorization for resumes and job description.
- **Similarity Scoring**: Cosine similarity to compute a score per candidate.
- **Database Logging**: Store candidate data and scores in SQLite.
- **Ranking Engine**: Export a ranked CSV of candidates.

## Project Structure

```text
resume-screening-bot/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ resumes/              # Input PDF resumes
â”‚   â”œâ”€â”€ jd/                   # Job description text files
â”‚   â””â”€â”€ samples/              # Optional sample skills lists, etc.
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ parser/
â”‚   â”‚   â”œâ”€â”€ pdf_reader.py     # PDF text extraction
â”‚   â”‚   â””â”€â”€ text_cleaner.py   # Clean, normalize text
â”‚   â”‚
â”‚   â”œâ”€â”€ nlp/
â”‚   â”‚   â”œâ”€â”€ skill_extractor.py  # Extract skills using NLP / patterns
â”‚   â”‚   â”œâ”€â”€ jd_processor.py     # Process job description
â”‚   â”‚   â””â”€â”€ vectorizer.py       # TF-IDF vectorization
â”‚   â”‚
â”‚   â”œâ”€â”€ engine/
â”‚   â”‚   â””â”€â”€ scorer.py         # Cosine similarity scoring
â”‚   â”‚
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ db_config.py
â”‚   â”‚   â””â”€â”€ db_operations.py  # Insert/retrieve candidates and JDs
â”‚   â”‚
â”‚   â”œâ”€â”€ automation/
â”‚   â”‚   â””â”€â”€ ranker.py         # Generate final ranking CSV
â”‚   â”‚
â”‚   â””â”€â”€ app.py                # Main pipeline entry point
â”‚
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ schema.sql            # Database schema
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ logger.py             # Simple logging wrapper
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ output/
    â””â”€â”€ ranked_candidates.csv # Generated after running the app
```

## Installation

1. Create and activate a virtual environment (recommended).
2. Install dependencies:

```bash
pip install -r requirements.txt
```

## Usage

1. Place resume PDF files in `data/resumes/`.
2. Place a job description text file (e.g. `jd.txt`) in `data/jd/`.
3. Run the main application from the project root:

```bash
python -m src.app
```

This will:

- Load the job description from `data/jd/` (first `.txt` file found).
- Parse and clean each PDF resume in `data/resumes/`.
- Extract skills and estimate experience.
- Vectorize resumes and JD using TF-IDF.
- Compute cosine similarity scores.
- Store candidates and scores in a SQLite DB file `resume_screening.db`.
- Export `output/ranked_candidates.csv` sorted by score (descending).

## Notes

- The implementation uses TF-IDF by default for simplicity and reliability.
- You can later extend `vectorizer.py` to plug in Sentence-BERT embeddings.
- OCR for image-based PDFs can be added on top of `pdf_reader.py` using Tesseract if needed.
